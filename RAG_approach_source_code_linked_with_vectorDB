import pandas as pd
import numpy as np
import os
import re
from  PyPDF2  import PdfReader
import json
from vector_db_1 import create_save_vector_db, load_vector_db
import pandas as pd
# from langchain.document_loaders.pdf import UnstructuredPDFLoader
from langchain_community.document_loaders import PyPDFLoader
from pathlib import Path
import textwrap
import google.generativeai as genai
from pypdf import PdfReader
import os
import json
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_community.vectorstores import FAISS
from langchain_google_genai import GoogleGenerativeAIEmbeddings
from langchain.chains import RetrievalQA
from langchain import PromptTemplate
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_community.document_loaders import PyPDFLoader
import shutil
# import PyPDF2
os.environ['GOOGLE_APPLICATION_CREDENTIALS']="C:/Users/2125065/Project_Gen/proj_gen/GCP/gbg-poc-migrate-0a6b122a1db6.json"
os.environ['GOOGLE_API_KEY']="AIzaSyD1M1zw-qvlctf2Mu-A_T54xtcMRH6k6Es"


from langchain_google_genai import ChatGoogleGenerativeAI
from google.generativeai.types import HarmCategory, HarmBlockThreshold
import google.generativeai as genai
import streamlit as st
import tempfile
# from gen_code import  get_gemini_hcr_2
from vector_db_1 import create_save_vector_db_with_text
 
from langchain_community.document_loaders import PyPDFLoader
 
 
 
def file_read(pdf_path):
    try:
        pdf_file_path = os.listdir(pdf_path)
        pdf_file_path = os.path.join(pdf_path,pdf_file_path[0])
        print(pdf_file_path)
        loader = PyPDFLoader(pdf_file_path)
        reader = loader.load_and_split()
        # reader = PdfReader(pdf_path)

        text_splitter = RecursiveCharacterTextSplitter(chunk_size=5000, chunk_overlap=400)
        context = "\n\n".join(str(p.page_content) for p in reader)
        # print(context)
        text = text_splitter.split_text(context)
        # print(text)
        return text
       
 
    except Exception as e :
        print(f"Error reading PDF: {e}")

 
def save_uploaded_file(uploadedfile):
    file_path = r"C:\Users\2125065\Project_Gen\proj_gen\rag_files"
    file_path = Path(file_path)
    shutil.rmtree(file_path) # remove existing dir 
    os.makedirs(file_path, exist_ok=True)
    with open(os.path.join(file_path, uploadedfile.name), "wb") as f:
        f.write(uploadedfile.getbuffer())
    # return (st.success(f"Saved file: {uploadedfile.name} in {file_path}"), file_path)    # print(pdf_path)
    print(file_path)
    return file_path
def generate_output(prompt):
    try:
        gen_config  = genai.GenerationConfig(temperature=0,top_p=0.9,top_k=3)


        safety_settings={
        HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_NONE,
        HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_NONE,
        }
        model = ChatGoogleGenerativeAI(model='gemini-pro', generation_config=gen_config, safety_settings=safety_settings)



        # model = ChatGoogleGenerativeAI(model='gemini-pro', generation_config=generation_config)
        # text_splitter = RecursiveCharacterTextSplitter(chunk_size=10000, chunk_overlap=1000)
        # isdir = os.path.isdir("VectorDB")
        # print(isdir)
        # if not isdir:    
        #     create_save_vector_db_with_text(txt)
        # context = "\n\n".join(str(p.page_content) for p in txt)
        # # print(context)
        # texts = text_splitter.split_text(context)
        # vector_index=load_vector_db()
        embeddings = embeddings = GoogleGenerativeAIEmbeddings(model="models/embedding-001")
        vector_index = FAISS.load_local("VectorDB", embeddings, allow_dangerous_deserialization=True)
        vector_index = vector_index.as_retriever(search_kwargs={"k":4})
        prompt = prompt 
        # print(txt)
        template = """Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer. Keep the answer as concise as possible.Try to generate answer in json format.
        {context}
        Question: {question}
        Helpful Answer:"""
        QA_CHAIN_PROMPT = PromptTemplate.from_template(template)# Run chain
        try:
             
            qa_chain = RetrievalQA.from_chain_type(
                model,
                retriever=vector_index,
                return_source_documents=True,
                chain_type_kwargs={"prompt": QA_CHAIN_PROMPT}
                )
            response = qa_chain({"query": prompt})
            response_text  = response["result"]
            print(response_text)
            # cleaned_txt = response_text.replace("\n","").replace("","")
            # cleaned_txt_done = json.loads(cleaned_txt)
        # df = pd.DataFrame(cleaned_txt_done)
            # return cleaned_txt_done
            return response_text
        except Exception as e:
            print(e)
 
    except Exception as e:
        print(f"Error generating content: {e}")
        return None
   
def main():
    st.title("PDF Text Generation")
 
    uploaded_file = st.file_uploader("Upload PDF", type = ["pdf"])
    user_prompt = st.text_input("Enter Prompt")
    try:

        if uploaded_file:
            pdf_path = save_uploaded_file(uploaded_file)
            # pdf_path = Path(pdf_path)
            txt = file_read(pdf_path)
            create_save_vector_db_with_text(txt)
            # user_prompt = st.text_input("Enter Prompt")
    
        if user_prompt:
            output_df =generate_output(user_prompt)
            if output_df is not None:
                st.write(output_df)
            else:
                    st.error("Error Genrating content.")
    except Exception as e:
        print(e)
 
if __name__ == "__main__":
    main()
